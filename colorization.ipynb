{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc41d06",
   "metadata": {},
   "source": [
    "We are implementing the Levin et al. (2004) colorization algorithm. \n",
    "\n",
    "The algorithm operates in $YUV$ space. Where The $Y$ represents the Luminance and the $U$,$V$ are the color channels. In our problem we will receive as the input image only a BW image with the $Y$ channel, and we need to solve the chrominance UV based on a marked image.\n",
    "Afterwards we will solve a sparse system of linear equations to propagate color from the user scribbles.\n",
    "\n",
    "Our implementation will use the following libraries:\n",
    "* `numpy`: Matrix operations.\n",
    "* `cv2` (OpenCV): Image I/O and RGB $\\leftrightarrow$ $YUV$ conversion.\n",
    "* `scipy.sparse`: Handling the large, sparse affinity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62267887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 2.2.6\n",
      "OpenCV: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "print(f\"OpenCV: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c6b6d",
   "metadata": {},
   "source": [
    "In the setup phase the images will be loaded and prepared. For this we must first normalize the images by converting them to `float64` in the range `[0, 1]`. This is critical for accurate variance calculations in the weighting function. Then we will convert them to the correct color space $YUV$. The algorithm uses the $Y$ channel from the original image and the $U, V$ values from the scribbles at marked locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8bee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep(image_path, scribbles_path):\n",
    "    img_gray_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img_scrib_bgr = cv2.imread(scribbles_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Normalize\n",
    "    img_gray = img_gray_bgr.astype(np.float64) / 255.0\n",
    "    img_scrib = img_scrib_bgr.astype(np.float64) / 255.0\n",
    "\n",
    "    # Convert to YUV\n",
    "    img_gray_yuv = cv2.cvtColor(img_gray.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "    img_scrib_yuv = cv2.cvtColor(img_scrib.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    return img_gray_yuv, img_scrib_yuv\n",
    "\n",
    "YUV_original, YUV_marked = load_and_prep(\"example.bmp\", \"example_marked.bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ce0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(name, image):\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # It is for removing/deleting created GUI window from screen and memory\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aaf3cd",
   "metadata": {},
   "source": [
    "This is the core of the Levin et al. algorithm. We treat the image as a graph where every pixel is a node connected to its neighbors.\n",
    "\n",
    "**The Objective:**\n",
    "We want to minimize the difference between a pixel's color $U(r)$ and the weighted average of its neighbors $U(s)$:\n",
    "$$J(U) = \\sum_{r} \\left( U(r) - \\sum_{s \\in N(r)} w_{rs} U(s) \\right)^2$$\n",
    "\n",
    "The weight $w_{rs}$ represents the similarity between two pixels. If their intensities $Y(r)$ and $Y(s)$ are similar, the weight is large (color propagates). If they are different (an edge), the weight is small.\n",
    "$$w_{rs} \\propto e^{-(Y(r) - Y(s))^2 / 2\\sigma_r^2}$$\n",
    "\n",
    "**The Linear System ($Ax=b$):**\n",
    "Since the cost function is quadratic, we can solve it by setting the derivative to zero, resulting in a sparse linear system:\n",
    "1.  **Constrained Pixels (Scribbles):** $U(r) = \\text{user\\_val}$.\n",
    "2.  **Unconstrained Pixels:** $U(r) - \\sum w_{rs} U(s) = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5599d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17405 constrained pixels.\n",
      "Building affinity matrix...\n"
     ]
    }
   ],
   "source": [
    "def get_weights_and_solve(Y_channel, marked_U, marked_V, mask):\n",
    "    \"\"\"\n",
    "    Y_channel: The intensity channel (H, W)\n",
    "    marked_U, marked_V: The U and V channels from the scribbled image\n",
    "    mask: Boolean matrix where True indicates a scribbled pixel\n",
    "    \"\"\"\n",
    "    H, W = Y_channel.shape\n",
    "    num_pixels = H * W\n",
    "    \n",
    "    # Identify Neighbors (3x3 Window)\n",
    "    # We iterate over the 3x3 window around each pixel to calculate weights\n",
    "    # dx, dy are offsets from the center pixel\n",
    "    window_range = [-1, 0, 1]\n",
    "    \n",
    "    # Lists to build the sparse matrix (LIL format concept, but using arrays for speed)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    \n",
    "    # Pre-calculate pixel indices\n",
    "    img_indices = np.arange(num_pixels).reshape(H, W)\n",
    "    \n",
    "    # To estimate sigma (variance) locally, we look at the window\n",
    "    # Simple approx: use mean variance or small constant if homogeneous\n",
    "    # Levin paper uses local variance. Here we use a global estimate for simplicity \n",
    "    # or a local window calculation. \n",
    "    # For this snippet, we'll use a simplified standard deviation logic.\n",
    "    \n",
    "    print(\"Building affinity matrix...\")\n",
    "    for dy in window_range:\n",
    "        for dx in window_range:\n",
    "            if dy == 0 and dx == 0:\n",
    "                continue # Skip self\n",
    "            \n",
    "            # Shift indices to find neighbors\n",
    "            # We identify valid neighbors (pixels that don't fall off the edge)\n",
    "            r_idx_y, r_idx_x = np.where(img_indices >= 0) # All pixels\n",
    "            # Neighbor coordinates\n",
    "            s_idx_y = r_idx_y + dy\n",
    "            s_idx_x = r_idx_x + dx\n",
    "            \n",
    "            # Filter valid bounds\n",
    "            valid = (s_idx_y >= 0) & (s_idx_y < H) & (s_idx_x >= 0) & (s_idx_x < W)\n",
    "            \n",
    "            # Valid center pixels (r) and neighbor pixels (s)\n",
    "            r_y, r_x = r_idx_y[valid], r_idx_x[valid]\n",
    "            s_y, s_x = s_idx_y[valid], s_idx_x[valid]\n",
    "            \n",
    "            # Flat indices for matrix construction\n",
    "            r_flat = img_indices[r_y, r_x]\n",
    "            s_flat = img_indices[s_y, s_x]\n",
    "            \n",
    "            # Calculate Weights\n",
    "            # w_rs = exp( - (Y(r) - Y(s))^2 / (2 * sigma^2) )\n",
    "            Y_r = Y_channel[r_y, r_x]\n",
    "            Y_s = Y_channel[s_y, s_x]\n",
    "            \n",
    "            diff_sq = (Y_r - Y_s) ** 2\n",
    "            sigma = 0.02 # Variance constant (tunable)\n",
    "            w_rs = np.exp(-diff_sq / (2 * sigma**2))\n",
    "            \n",
    "            # Store triplet\n",
    "            rows.extend(r_flat)\n",
    "            cols.extend(s_flat)\n",
    "            data.extend(-w_rs) # Negative because usually (I - W)x = 0\n",
    "\n",
    "    # Create the sparse matrix A\n",
    "    # Shape: (N, N)\n",
    "    A = sparse.coo_matrix((data, (rows, cols)), shape=(num_pixels, num_pixels)).tolil()\n",
    "    \n",
    "    # Normalize rows (so weights sum to 1) and add diagonal\n",
    "    # The diagonal is 1.0 (representing U(r))\n",
    "    # Currently A has -w_rs. We need to normalize these weights.\n",
    "    \n",
    "    # Sum of weights per row\n",
    "    sum_weights = np.abs(A.sum(axis=1).A.flatten())\n",
    "    # Avoid division by zero\n",
    "    sum_weights[sum_weights == 0] = 1.0 \n",
    "    \n",
    "    # Normalize A: divide each row by its sum\n",
    "    # Using dia_matrix for efficient row scaling\n",
    "    D_inv = sparse.diags(1.0 / sum_weights)\n",
    "    A = D_inv @ A\n",
    "    \n",
    "    # Set diagonal to 1.0\n",
    "    A.setdiag(1.0)\n",
    "    \n",
    "    # Apply Constraints (Scribbles)\n",
    "    # For marked pixels, the equation is U(r) * 1 = marked_val\n",
    "    # We replace the entire row in A with [0...0 1 0...0]\n",
    "    \n",
    "    mask_flat = mask.flatten()\n",
    "    constrained_indices = np.where(mask_flat)[0]\n",
    "    \n",
    "    # Zero out rows for constrained pixels to remove neighbor influence\n",
    "    # This is a slow operation in LIL, usually done better by constructing A with constraints known\n",
    "    # But for clarity:\n",
    "    A[constrained_indices, :] = 0\n",
    "    A[constrained_indices, constrained_indices] = 1.0\n",
    "    \n",
    "    # Construct b vectors\n",
    "    b_u = np.zeros(num_pixels)\n",
    "    b_v = np.zeros(num_pixels)\n",
    "    \n",
    "    # Set values for constrained pixels\n",
    "    flat_U = marked_U.flatten()\n",
    "    flat_V = marked_V.flatten()\n",
    "    \n",
    "    b_u[constrained_indices] = flat_U[constrained_indices]\n",
    "    b_v[constrained_indices] = flat_V[constrained_indices]\n",
    "    \n",
    "    # 6. Solve\n",
    "    print(\"Solving linear system (this may take a moment)...\")\n",
    "    A_csr = A.tocsr()\n",
    "    final_u = spsolve(A_csr, b_u)\n",
    "    final_v = spsolve(A_csr, b_v)\n",
    "    \n",
    "    return final_u.reshape(H, W), final_v.reshape(H, W)\n",
    "\n",
    "# Run the solver\n",
    "# Define mask: where does the scribble image differ from the BW image?\n",
    "# We look for pixels where color exists (U or V is not 0 or 0.5 depending on range)\n",
    "# In normalized YUV (0-1), gray is typically around 0.5 for U and V.\n",
    "# Let's assume significant deviation from the original YUV means a scribble.\n",
    "diff = np.abs(YUV_marked - YUV_original)\n",
    "# Sum diff over U and V channels\n",
    "is_scribbled = (diff[:,:,1] + diff[:,:,2]) > 0.01\n",
    "\n",
    "print(f\"Found {np.sum(is_scribbled)} constrained pixels.\")\n",
    "\n",
    "# Solve\n",
    "solved_u, solved_v = get_weights_and_solve(YUV_original[:,:,0], YUV_marked[:,:,1], YUV_marked[:,:,2], is_scribbled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
